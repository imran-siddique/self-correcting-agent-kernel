\documentclass{article}

% -- PACKAGES --
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}       % figures
\usepackage{geometry}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{listings}

% -- TIKZ FOR FIGURES --
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning, calc, fit}

% -- HYPERLINKS SETUP --
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue,
}

% -- GEOMETRY --
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}

\title{Self-Correcting Agent Kernel: Automated Alignment via Differential Auditing and Semantic Memory Hygiene}

% -- ANONYMIZED AUTHORS FOR DOUBLE-BLIND REVIEW --
\author{
  Anonymous Authors \\
  Affiliation \\
  \texttt{email@domain.com} \\
}

\date{}

\begin{document}

\maketitle

% -- LLM DISCLOSURE --
\let\thefootnote\relax\footnotetext{Disclosure: Large Language Models (GPT-4o, Claude 3.5 Sonnet) were used for grammatical checking and minor copy-editing of this manuscript. All novel scientific contributions, experimental designs, and data analyses are original to the authors.}

\begin{abstract}
Production AI agents face a ``Reliability Wall'' defined by two invisible pathologies: \textbf{laziness} (premature give-ups on achievable tasks) and \textbf{context rot} (performance degradation due to accumulated prompt instructions). Existing architectures often exacerbate these issues by treating ``more context'' as the solution to every failure, leading to the \textit{Accumulation Paradox}. We present the \textbf{Self-Correcting Agent Kernel (SCAK)}, a dual-loop OODA architecture grounded in the principle of \textit{Scale by Subtraction}. SCAK's Runtime Loop ensures deterministic safety, while the Alignment Loop implements \textbf{Differential Auditing}: a probabilistic mechanism that compares a weak agent (GPT-4o) against a stronger teacher (o1-preview) only on ``give-up signals'' (5--10\% of interactions). This catches capability failures that explicit error handlers miss. To combat context rot, we introduce \textbf{Semantic Purge}: a formal decay taxonomy where ``Type A'' (syntax) patches are actively deleted on model upgrades, while ``Type B'' (business) knowledge persists. Evaluations on GAIA benchmark extensions demonstrate \textbf{100\% laziness detection} and a \textbf{72\% correction rate} ($p<0.001$) at 90\% lower cost than full verification. Chaos engineering tests show a \textbf{$<30s$ Mean Time To Recovery (MTTR)}, validating that reliability stems not from infinite memory, but from hygienic forgetting.
\end{abstract}

\section{Introduction}

\subsection{The Accumulation Paradox}
The prevailing dogma in agentic AI is \textit{accumulation}: if an agent fails, we add a rule; if it lacks knowledge, we expand the context window. While context windows have grown from 8K to 1M tokens, agent reliability has not followed a linear trajectory. Instead, we observe the \textbf{Accumulation Paradox}: as system prompts grow to cover edge cases, agents suffer from ``fog of context,'' leading to instruction conflicts and increased latency \cite{liu2023lost}.

Simultaneously, deployed agents exhibit \textbf{laziness}---a capability failure disguised as compliance. When faced with ambiguous queries or rate limits, agents default to low-energy responses (``I couldn't find any data'') rather than attempting robust retry strategies. Standard monitoring, which looks for explicit exceptions (HTTP 500), is blind to these semantic failures. In production systems, we estimate 15--30\% of unsatisfying responses stem from this implicit laziness.

\subsection{Scale by Subtraction}
We propose that long-term reliability requires \textbf{Scale by Subtraction}: the architectural principle that an agent improves not just when it learns a new skill, but when it successfully \textit{forgets} a temporary dependency. 

To this end, we introduce the \textbf{Self-Correcting Agent Kernel (SCAK)}, a system that differs from prior work through three novel contributions:

\begin{enumerate}
    \item \textbf{Type-Aware Semantic Purge:} We are the first to introduce a formal decay taxonomy for learned instructions. SCAK treats competence patches as decaying assets: \textit{Type A} (syntax/capability) patches are automatically deleted on model upgrades, while \textit{Type B} (business logic) patches persist. This achieves \textbf{40--60\% context reduction} compared to the unbounded growth of Reflexion \cite{shinn2023reflexion}.
    
    \item \textbf{Differential Auditing ($P_{audit}$):} Unlike RLHF which samples uniformly, or safety guardrails which audit strictly for harm, we introduce \textit{Differential Auditing} for capabilities. By activating a strong ``teacher'' model only upon detection of semantic ``give-up'' signals (5--10\% of interactions), we achieve \textbf{100\% laziness detection} at 90\% lower cost than full-trace verification.
    
    \item \textbf{Secure Dual-Loop OODA:} Addressing recent critiques of OODA loops as security vulnerabilities \cite{schneier2026ooda}, we decouple the \textbf{Runtime Loop} (fast, safety-constrained) from the \textbf{Alignment Loop} (slow, teacher-verified). This ensures that untrusted user inputs cannot permanently corrupt the agent's core instructions without rigorous, asynchronous verification.
\end{enumerate}

While SCAK focuses on the \textit{internal} alignment and capability restoration of the agent (Loop 2), the enforcement of strict safety boundaries and access control is handled by the \textbf{Agent Control Plane}. We refer readers to our concurrent work \cite{anonymous2026acp} for details on the runtime governance mechanisms (Loop 1) that complement SCAK's self-correction.

\section{System Design}

\subsection{Problem Formulation}
Let an agent policy $\pi_\theta$ generate a response $y$ given context $C$ and query $x$. We define two failure modes:
\begin{enumerate}
    \item \textbf{Laziness ($\mathcal{L}$):} $\pi_\theta(x)$ returns a null result (e.g., ``Unknown'') when a valid result $y^*$ exists such that $V(y^*) > \epsilon$.
    \item \textbf{Context Rot ($\mathcal{R}$):} The performance metric $M(\pi_{\theta, C})$ degrades as $|C| \to \infty$.
\end{enumerate}
Our objective is to maximize $M$ while minimizing $|C|$ and eliminating $\mathcal{L}$.

\subsection{Dual-Loop Architecture}
SCAK implements the OODA loop as two concurrent processes (Figure \ref{fig:ooda}):
